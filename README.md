# Youtube_DataEngineering_project
# OVERVIEW
Azure Data Factory automates data movement, Data Lake Gen2 provides secure storage, Databricks transforms data for analytics, Synapse Analytics powers large-scale analytics, and Power BI creates user-friendly dashboards.


# PROJECT GOAL
1. Data Ingestion
2. ETL System
3. Data lake
4. Scalability
5. Cloud (AZURE)
6. Reporting (Dashboard)


1. **Data Ingestion:**
   - Initiated by Azure Data Factory, responsible for orchestrating the extraction process from the on-premises database to the Azure Cloud. It ensures a smooth and automated flow of data.

2. **ETL System:**
   - Azure Databricks, a collaborative Apache Spark-based analytics platform, is employed for Extract, Transform, Load (ETL) operations. This phase focuses on refining and structuring the extracted data for further analysis.

3. **Data Lake:**
   - Azure Data Lake Gen2 serves as the storage solution, providing a scalable and secure environment for storing diverse datasets. The data lake architecture facilitates flexibility in handling structured and unstructured data.

4. **Scalability:**
   - Scalability is addressed through Azure services such as Data Lake Gen2 and Synapse Analytics. These services are designed to handle growing data volumes, ensuring the system's ability to scale seamlessly as data requirements increase.

5. **Cloud (Azure):**
   - The entire data migration and analytics pipeline operate within the Azure cloud environment. Leveraging Azure's infrastructure, security, and management services contribute to the reliability and efficiency of the entire process.

6. **Reporting (Dashboard):**
   - Power BI is employed to create a user-friendly dashboard for reporting, visualization, and analysis. This enables stakeholders to derive actionable insights from the transformed and processed data, enhancing decision-making capabilities.


# USED SERVICES
1. **Azure Data Factory:**
   - A cloud-based ETL (Extract, Transform, Load) service by Microsoft Azure, facilitating the automated and orchestrated movement of data between on-premises and cloud environments. It serves as the initial data ingestion point in the pipeline.

2. **Azure Data Lake Gen2:**
   - A scalable and secure data lake storage solution on Azure, capable of handling large amounts of structured and unstructured data. It is utilized as the storage repository for the extracted data.

3. **Azure Databricks:**
   - A collaborative Apache Spark-based analytics platform on Azure for big data processing and machine learning. In the pipeline, it is employed for data transformation, preparing the data for advanced analytics and insights.

4. **Azure Synapse Analytics:**
   - Formerly known as Azure SQL Data Warehouse, this service is used for large-scale analytics and data warehousing. It is the destination for the migrated and refined data, optimizing performance and scalability in analytics processing.

5. **Power BI:**
   - A business analytics tool by Microsoft used for creating interactive reports and dashboards. In this pipeline, Power BI is employed to construct a user-friendly dashboard for visualization and analysis, providing actionable insights.

These tools and services collectively form an end-to-end solution for data migration, transformation, storage, and analysis within the Azure cloud environment.

 #   ARCHITECTURE

![Azure Data Maigration flow](https://github.com/somnath-2001/Azure_Data_Migration_Engineering_project/assets/118129457/506a49b6-e37e-4750-96d2-b6177e42faee)

